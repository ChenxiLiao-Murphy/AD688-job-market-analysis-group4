{
  "hash": "a56ffe67b86c13ca0219785f41b61474",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Modeling & Analysis\"\nformat:\n  html:\n    toc: true\n    code-fold: true\nbibliography: references.bib\ncsl: csl/econometrica.csl\nexecute:\n    echo: true\n    eval: false\n    freeze: auto\n---\n\n# Introduction\n\nThis section presents our machine learning models to analyze geographic and remote work patterns in the 2024 U.S. job market. We apply both **unsupervised** and **supervised** learning methods to gain insights into how job locations and remote types impact salaries and job classifications.\n\n---\n\n# Unsupervised Learning: KMeans Clustering\n\nTo better understand remote work trends, we used KMeans clustering to group job postings based on three key features: `STATE_NAME`, `REMOTE_TYPE_NAME`, and `SOC_2021_4`. These variables capture geographic and job-type information, helping us explore whether certain kinds of work—remote, hybrid, or on-site—are more common in particular states or industries. The clustering results, visualized using PCA, reveal clear patterns related to both location and remote work preferences. These insights can be useful for job seekers trying to identify which types of roles or industries are more likely to support flexible work arrangements.\n\n::: {#fa3be461 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\")\nprint(df.columns.tolist())\n```\n:::\n\n\n::: {#9a2feefd .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# STEP 1: Load your cleaned dataset\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\") \n\n# STEP 2: Select columns\ncols = ['STATE_NAME', 'REMOTE_TYPE_NAME', 'SOC_2021_4']\ndf_cluster = df[cols].dropna()\ndf_cluster_encoded = pd.get_dummies(df_cluster)\n\n# STEP 3: Scale and cluster\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(df_cluster_encoded)\n\nkmeans = KMeans(n_clusters=4, random_state=42)\nclusters = kmeans.fit_predict(X_scaled)\ndf_cluster['Cluster'] = clusters\n\n# STEP 4: Visualize with PCA\npca = PCA(n_components=2)\ncomponents = pca.fit_transform(X_scaled)\n\nplt.figure(figsize=(8,6))\nplt.scatter(components[:, 0], components[:, 1], c=clusters, cmap='Set2')\nplt.title(\"KMeans Clusters by Location and Remote Type\")\nplt.xlabel(\"PCA Component 1\")\nplt.ylabel(\"PCA Component 2\")\n\n# save the figure\nplt.tight_layout()\nplt.savefig(\"figuresmurphy/kmeans_location_remote_pca.png\", dpi=300)\n\nplt.show()\n```\n:::\n\n\n![](figuresmurphy/kmeans_location_remote_pca.png){width=80% fig-align='center' fig-cap=\"KMeans Clusters by Location and Remote Type\"}\n\n**Interpretation:**\nThe PCA scatter plot reveals four distinct clusters of job postings, segmented by location (STATE_NAME),  remote type (REMOTE_TYPE_NAME), and occupation code (SOC_2021_4).\nWe see a clear separation among the clusters—three are relatively compact,  while one appears more dispersed. This indicates that job characteristics like remote work availability and occupation  type tend to align closely with geographic regions and specific industries. The tightly grouped clusters likely  represent roles with consistent remote work policies,  while the spread-out cluster may include a broader mix of job types.\n\n\n## Supervised Learning: Classification – Predict Remote Type\n\nTo understand what factors influence whether a job is remote, hybrid, or on-site, we trained a Random Forest Classifier using three features: `STATE_NAME` (location), `SOC_2021_4` (job category), and `MAX_YEARS_EXPERIENCE` (seniority level).The model's performance is summarized in a confusion matrix, which shows how accurately it distinguishes between different types of remote work arrangements.\n\n::: {#a66a23c8 .cell execution_count=3}\n``` {.python .cell-code}\n# Import libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Prepare dataset\ndf_class = df[['STATE_NAME', 'SOC_2021_4', 'MAX_YEARS_EXPERIENCE', 'REMOTE_TYPE_NAME']].dropna()\ndf_class_encoded = pd.get_dummies(df_class, columns=['STATE_NAME', 'SOC_2021_4'])\n\nX = df_class_encoded.drop('REMOTE_TYPE_NAME', axis=1)\ny = df_class['REMOTE_TYPE_NAME']\n\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Train classifier\nclf = RandomForestClassifier(random_state=42)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\n# Print performance\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n\n\n# Visualize confusion matrix\nplt.figure(figsize=(6,5))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix - Remote Work Type Classifier\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.tight_layout()\n\n# Save\nplt.savefig(\"figuresmurphy/confusion_matrix_remote_type.png\", dpi=300)\nplt.show()\n```\n:::\n\n\n![](figuresmurphy/confusion_matrix_remote_type.png){width=100% fig-align='center' fig-cap=\"Confusion Matrix of Random Forest Classifier for Remote Work Type\"}\n\n**Interpretation:**\nThe model accurately predicts class 3, but often misclassifies classes 0, 1, and 2 as 3,  showing a bias toward the most common remote type. Job seekers should clearly state remote preferences,  as nuanced roles may be missed by automated systems.\n\n\n## Supervised Learning: Regression – Predict Salary\n\nWe applied a Random Forest Regressor to estimate average salary using location, experience, remote type, and job category. The model captures complex patterns, highlighting how these factors shape compensation.\n\n::: {#959eeccc .cell execution_count=4}\n``` {.python .cell-code}\n# Step 1: Create AVERAGE_SALARY if not already in df\ndf['SALARY_FROM'] = pd.to_numeric(df['SALARY_FROM'], errors='coerce')\ndf['SALARY_TO'] = pd.to_numeric(df['SALARY_TO'], errors='coerce')\ndf['AVERAGE_SALARY'] = (df['SALARY_FROM'] + df['SALARY_TO']) / 2\n\n# Step 2: Drop rows with missing values in key columns\ndf_reg = df[['STATE_NAME', 'SOC_2021_4', 'REMOTE_TYPE_NAME', 'MAX_YEARS_EXPERIENCE', 'AVERAGE_SALARY']].dropna()\n\n# Step 3: One-hot encoding\ndf_reg_encoded = pd.get_dummies(df_reg, columns=['STATE_NAME', 'SOC_2021_4', 'REMOTE_TYPE_NAME'])\n\n# Step 4: Split X and y\nX = df_reg_encoded.drop('AVERAGE_SALARY', axis=1)\ny = df_reg_encoded['AVERAGE_SALARY']\n\n# Step 5: Train/test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Step 6: Train Random Forest Regressor\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Step 7: Predict\ny_pred = model.predict(X_test)\n\n# Step 8: Evaluate\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nprint(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\nprint(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\nprint(\"R2 Score:\", r2_score(y_test, y_pred))\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(6,6))\nplt.scatter(y_test, y_pred, alpha=0.5)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\nplt.xlabel(\"Actual Salary\")\nplt.ylabel(\"Predicted Salary\")\nplt.title(\"Actual vs Predicted Salary\")\nplt.tight_layout()\nplt.savefig(\"figuresmurphy/actual_vs_predicted_salary.png\", dpi=300)\nplt.show()\n```\n:::\n\n\n![](figuresmurphy/actual_vs_predicted_salary.png){width=100% fig-align='center' fig-cap=\"Actual vs. Predicted Salary by Random Forest\"}\n\n**Interpretation:**\nThe plot shows a strong alignment between predicted and actual salaries, with most points near the red dashed line—indicating good model performance. Some deviations, especially in higher salary ranges, reflect the difficulty of predicting roles with greater variability in seniority and industry.\n\n\n\n## Which states are more inclined to offer Remote/Hybrid/Onsite jobs?\n\n::: {#48bd4267 .cell execution_count=5}\n``` {.python .cell-code}\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf_geo = df[['STATE_NAME', 'REMOTE_TYPE_NAME']].dropna()\n\n）\nstate_remote_counts = pd.crosstab(df_geo['STATE_NAME'], df_geo['REMOTE_TYPE_NAME'])\n\n# visualization\nstate_remote_counts.plot(kind='bar', stacked=True, figsize=(14,6))\nplt.title(\"Remote Work Type Distribution by State\")\nplt.xlabel(\"State\")\nplt.ylabel(\"Number of Job Postings\")\nplt.xticks(rotation=90)\nplt.tight_layout()\n\n\nplt.savefig(\"figuresmurphy/remote_type_by_state.png\", dpi=300)\nplt.show()\n```\n:::\n\n\n![Remote Work Type by State](figuresmurphy/remote_type_by_state.png){width=100% fig-align='center' fig-cap=\"Distribution of Remote Work Type Across States\"}\n\n**Interpretation:**\nThe bar chart shows that states like California, New York, and Texas have a high volume of job postings across all remote types. Remote roles are especially common in tech-focused states like California and Washington, while on-site jobs are more prevalent in states with stronger manufacturing industries.\n\n\n\n# Which type of remote work offers a higher salary? \nWe used a boxplot to compare salaries across remote types, helping job seekers understand potential income differences between remote, hybrid, and on-site roles.\n\n::: {#8df56208 .cell execution_count=6}\n``` {.python .cell-code}\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# deal with salary list\ndf_salary = df[['REMOTE_TYPE_NAME', 'SALARY']].dropna()\ndf_salary = df_salary[df_salary['SALARY'] < 300000]  # 过滤异常值（可选）\n\n\nplt.figure(figsize=(8,6))\nsns.boxplot(data=df_salary, x='REMOTE_TYPE_NAME', y='SALARY')\nplt.title(\"Salary Distribution by Remote Work Type\")\nplt.xlabel(\"Remote Work Type\")\nplt.ylabel(\"Salary\")\nplt.tight_layout()\n\nplt.savefig(\"figuresmurphy/salary_by_remote_type.png\", dpi=300)\nplt.show()\n```\n:::\n\n\n![Salary by Remote Type](figuresmurphy/salary_by_remote_type.png){width=100% fig-align='center' fig-cap=\"Boxplot of Salary Distribution Across Remote Work Types\"}\n\n**Interpretation:**\nRemote roles generally show a higher median salary than hybrid or on-site positions. However, the range is wider,  indicating more salary volatility. On-site jobs show tighter salary ranges,  likely due to standardized pay scales in location-bound industries.\n\n::: {#384c1cd6 .cell execution_count=7}\n``` {.python .cell-code}\nremote_ratio_by_state.sort_values('REMOTE_RATIO', ascending=False).head(10)\n```\n:::\n\n\n## Choropleth or map-based visualizations\nWe used a choropleth map to visually represent the percentage of remote jobs per state. This spatial analysis can guide job seekers toward states with more flexible work environments.\n\n::: {#2499b9f2 .cell execution_count=8}\n``` {.python .cell-code}\nimport pandas as pd\nimport plotly.express as px\nimport pandas as pd\nimport plotly.express as px\n\n# 1. Create a full name -> abbreviation mapping table\nstate_abbrev_map = {\n    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA',\n    'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA',\n    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA',\n    'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n    'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH',\n    'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC',\n    'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA',\n    'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN',\n    'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA',\n    'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'\n}\n\n# 2. Add a column of state abbreviations\nremote_ratio_by_state['STATE_ABBR'] = remote_ratio_by_state['STATE_NAME'].map(state_abbrev_map)\n\nprint(remote_ratio_by_state[['STATE_NAME', 'STATE_ABBR']].head())\n\nfig = px.choropleth(\n    remote_ratio_by_state,\n    locations='STATE_ABBR',\n    locationmode='USA-states',\n    color='REMOTE_RATIO',\n    scope='usa',\n    color_continuous_scale='Blues',\n    title='Proportion of Remote Jobs by State (Using State Abbreviations)',\n    width=1000,      \n    height=600       \n)\nfig.write_image(\"figuresmurphy/choropleth.png\", scale=2)\n\nfig.show()\n```\n:::\n\n\n![](figuresmurphy/choropleth.png){width=100% fig-align='center' fig-cap=\"Choropleth Map: Proportion of Remote Jobs by State\"}\n\n**Interpretation:**\nThe map highlights that coastal and urban states like California, New York,  and Massachusetts have more remote roles. In contrast, Midwest and Southern states show fewer remote postings,  likely due to a stronger focus on in-person or manufacturing jobs.\n\n\n\n\n## Logistic Regression: Binary Classification (Remote vs Non-Remote)\nTo identify what influences whether a job is remote, we used a logistic regression model. The confusion matrix below summarizes how well the model classifies remote and non-remote roles.\n\n::: {#e30eb919 .cell execution_count=9}\n``` {.python .cell-code}\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# 1. Preprocessing\ndf_logistic = df[['STATE_NAME', 'MAX_YEARS_EXPERIENCE', 'AVERAGE_SALARY', 'REMOTE_TYPE_NAME']].dropna()\n\ndf_logistic['REMOTE_TYPE_CLEANED'] = df_logistic['REMOTE_TYPE_NAME'].map({\n    'Remote': 'Remote',\n    'Hybrid Remote': 'Hybrid',\n    'Not Remote': 'Onsite'\n}).fillna('Onsite')\n\n# Create binary classification target\ndf_logistic['IS_REMOTE'] = df_logistic['REMOTE_TYPE_CLEANED'].apply(lambda x: 1 if x == 'Remote' else 0)\n\n# 2. One-hot encode state name\ndf_encoded = pd.get_dummies(df_logistic, columns=['STATE_NAME'], drop_first=True)\n\n# 3. Split data\nX = df_encoded.drop(['IS_REMOTE', 'REMOTE_TYPE_NAME', 'REMOTE_TYPE_CLEANED'], axis=1)\ny = df_encoded['IS_REMOTE']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# 4. Train model\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n# 5.  Evaluation\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n\n# 6. Visualize confusion matrix\nplt.figure(figsize=(6,4))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix 热力图\")\nplt.xlabel(\"预测值 Predicted\")\nplt.ylabel(\"实际值 Actual\")\nplt.tight_layout()\nplt.savefig(\"figuresmurphy/logistic_confusion_matrix.png\", dpi=300)\nplt.show()\n```\n:::\n\n\n![](figuresmurphy/logistic_confusion_matrix.png){width=100% fig-align='center' fig-cap=\"Logistic Regression Confusion Matrix\"}\n\n**Interpretation:**\nThe model accurately distinguishes remote from non-remote jobs, performing better on non-remote roles. Some misclassifications remain, so job seekers in flexible roles should clearly state their work preferences.\n\n\n# Modeling Requirements\n## Linear Regression\nWe also used a linear regression model to predict average salary based on location, experience, and remote type. The actual vs. predicted plot and residuals histogram below show the model’s performance.\n\n::: {#6be2cdfb .cell execution_count=10}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\n\n# 1. 预处理 Preprocessing\ndf_reg = df[['STATE_NAME', 'MAX_YEARS_EXPERIENCE', 'REMOTE_TYPE_NAME', 'AVERAGE_SALARY']].dropna()\ndf_reg = df_reg[df_reg['AVERAGE_SALARY'] < 300000]  # 去除极端值 Remove salary outliers\n\ndf_reg['REMOTE_TYPE_CLEANED'] = df_reg['REMOTE_TYPE_NAME'].map({\n    'Remote': 'Remote',\n    'Hybrid Remote': 'Hybrid',\n    'Not Remote': 'Onsite'\n}).fillna('Onsite')\n\n# 2. One-hot 编码 One-hot encode\ndf_reg_encoded = pd.get_dummies(df_reg, columns=['STATE_NAME', 'REMOTE_TYPE_CLEANED'], drop_first=True)\n\n# 3. 拆分数据 Split data\nX = df_reg_encoded.drop(['REMOTE_TYPE_NAME', 'AVERAGE_SALARY'], axis=1)\ny = df_reg_encoded['AVERAGE_SALARY']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# 4. 建模 Train model\nreg_model = LinearRegression()\nreg_model.fit(X_train, y_train)\ny_pred = reg_model.predict(X_test)\n\n# 5. 评估 Evaluation\nprint(\"MSE:\", mean_squared_error(y_test, y_pred))\nprint(\"R-squared:\", r2_score(y_test, y_pred))\n\n# 6. 可视化 - 实际 vs 预测工资散点图 Scatterplot of actual vs predicted\nplt.figure(figsize=(6, 5))\nplt.scatter(y_test, y_pred, alpha=0.5)\nplt.xlabel(\"实际工资 Actual Salary\")\nplt.ylabel(\"预测工资 Predicted Salary\")\nplt.title(\"实际 vs 预测工资散点图 (Actual vs. Predicted Salary)\")\nplt.tight_layout()\nplt.savefig(\"figuresmurphy/regression_actual_vs_predicted.png\", dpi=300)\nplt.show()\n\n# 7. 可视化 - 残差分布图 Residuals histogram\nresiduals = y_test - y_pred\nplt.figure(figsize=(6, 4))\nplt.hist(residuals, bins=30, color='orange', edgecolor='black')\nplt.title(\"残差分布图 Residuals Histogram\")\nplt.xlabel(\"残差 Residuals\")\nplt.ylabel(\"频率 Frequency\")\nplt.tight_layout()\nplt.savefig(\"figuresmurphy/regression_residuals.png\", dpi=300)\nplt.show()\n```\n:::\n\n\n![](figuresmurphy/regression_actual_vs_predicted.png){width=100% fig-align='center' fig-cap=\"Actual vs. Predicted Salary by Linear Regression\"}\n\n**Interpretation:**\nThe plot shows a clear linear trend but with greater dispersion compared to the random forest model, indicating that linear regression struggles to capture more complex salary patterns.\n\n\n![](figuresmurphy/regression_residuals.png){width=70% fig-align='center' fig-cap=\"Residuals Histogram of Linear Regression\"}\n\n**Interpretation:**\nThe residuals histogram is roughly normal and centered around zero, suggesting no major bias. However, the spread shows that predictions can vary by several thousand dollars based on the input features.\n\n",
    "supporting": [
      "ml_analysis_files"
    ],
    "filters": [],
    "includes": {}
  }
}