---
title: "Data Cleaning"
subtitle: "Data Preparation and Exploratory Insights for Geographic and Remote Work Trends"

bibliography: references.bib
csl: csl/econometrica.csl
format: 
  html:
    toc: true
    number-sections: true
    df-print: paged
---


# Data Cleaning & Exploration

This page provides an overview of the data cleaning and initial exploration process for the job market dataset.

_Content will be added here._




## 1. Load Dataset
```{python}
#| echo: true
#| eval: false
#| code-fold: true
#| results: hide

import pandas as pd
df1 = pd.read_csv("./data/lightcast_job_postings.csv")
```

```{python}
#| echo: true
#| eval: false
#| code-fold: true
#| results: hide

df1.head()
df1.info()
df1.describe()
```


##  Check Columns' Information 
```{python}
#| echo: true
#| eval: false
#| code-fold: true
#| results: hide
df1.columns.tolist()
print(df1.columns.tolist())
```

##  Dropping Unnecessary Columns
```{python}
#| echo: true
#| eval: false
#| code-fold: true
#| results: hide

# Define columns that are irrelevant or redundant for our analysis
columns_to_drop = [
    # Tracking and metadata
    "ID", "LAST_UPDATED_DATE", "LAST_UPDATED_TIMESTAMP", "DUPLICATES",
    "URL", "ACTIVE_URLS", "ACTIVE_SOURCES_INFO", "SOURCE_TYPES", "SOURCES",

    # Company raw info
    "COMPANY_RAW", "COMPANY_IS_STAFFING",

    # Raw or text-heavy fields
    "TITLE_RAW", "BODY",

    # Modeled / derived fields
    "MODELED_EXPIRED", "MODELED_DURATION",

    # Educational levels (redundant versions)
    "EDUCATION_LEVELS", "EDUCATION_LEVELS_NAME",
    "MIN_EDULEVELS", "MIN_EDULEVELS_NAME", "MAX_EDULEVELS",

    # Redundant NAICS / SOC codes
    "NAICS_2022_2", "NAICS_2022_2_NAME",
    "NAICS_2022_3", "NAICS_2022_3_NAME",
    "SOC_2", "SOC_3", "SOC_5"
]

# Drop columns, ignore if a column is missing
df1.drop(columns=columns_to_drop, inplace=True, errors="ignore")

# Display the first few rows to confirm
df1.head()
```


##  Handling Missing Values

```{python}
#| echo: true
#| eval: false
#| code-fold: true
#| results: hide

import seaborn as sns
import matplotlib.pyplot as plt
import os
os.makedirs("figureswxw", exist_ok=True)

```


```{python}
#| echo: true
#| eval: false
#| code-fold: true
#| label: "Missing Value Heatmap"
#| fig-cap: "Missing values in the dataset"
#| fig-align: center

import missingno as msno
import matplotlib.pyplot as plt
msno.heatmap(df1)

plt.title("Missing Values Heatmap")
plt.tight_layout()
plt.savefig("figureswxw/missing_values_heatmap.png", dpi=300)
plt.show()

```

![](figureswxw/missing_values_heatmap.png){width=100% fig-align='center'}


```{python}
#| echo: true
#| eval: false
#| code-fold: true

# Drop columns with >50% missing values
df1.dropna(axis=1, thresh=len(df1) * 0.5, inplace=True)


if "SALARY" in df1.columns:
    df1["SALARY"] = df1["SALARY"].fillna(df1["SALARY"].median())

    df1["DURATION"] = df1["DURATION"].fillna(df1["DURATION"].median())

categorical_columns = ["REMOTE_TYPE_NAME", "COMPANY_NAME", "MAX_EDULEVELS_NAME"]

for col in categorical_columns:
    if col in df1.columns:
        df1[col] = df1[col].fillna("Unknown")


df1.info()
```


##  Remove Duplicates
```{python}
#| echo: true
#| eval: false
#| code-fold: true
#| results: hide


df1.drop_duplicates(subset=["TITLE_CLEAN", "COMPANY_NAME", "CITY_NAME", "POSTED"], inplace=True)

df1["REMOTE_TYPE_NAME"].value_counts(dropna=False)
df1["EMPLOYMENT_TYPE_NAME"].value_counts(dropna=False)

```


```{python}
#| echo: true
#| eval: false
#| code-fold: true
#| results: hide

#improve

df1["EMPLOYMENT_TYPE_NAME"] = df1["EMPLOYMENT_TYPE_NAME"].replace({
    "Part-time (â‰¤ 32 hours)": "Part-time (≤ 32 hours)",
    "Part-time / full-time": "Part-time / Full-time"
})
df1["EMPLOYMENT_TYPE_NAME"] = df1["EMPLOYMENT_TYPE_NAME"].fillna("Unknown")
df1["EMPLOYMENT_TYPE_NAME"].value_counts()

```

```{python}
#| echo: true
#| eval: false
#| code-fold: true
#| freeze: true

#double check

categorical_columns = [
    "EMPLOYMENT_TYPE_NAME",
    "REMOTE_TYPE_NAME",
    "COMPANY_NAME",
    "STATE_NAME",
    "CITY_NAME",
    "MAX_EDULEVELS_NAME"
]

for col in categorical_columns:
    if col in df1.columns:
        print(f"Unique values in {col}:")
        print(df1[col].value_counts(dropna=False))
        print("-" * 40)


```



# Exploratory Data Analysis


##   Remote Type distribution
```{python}
#| echo: true
#| eval: false
#| code-fold: true
#| lable: "Remote type distribution Graph"
#| fig-align: center
#| fig-cap: "Remote type distribution"


remote_counts = df1["REMOTE_TYPE_NAME"].value_counts()

plt.figure(figsize=(10,6))
ax = sns.barplot(
    x=remote_counts.index, 
    y=remote_counts.values, 
    hue=remote_counts.index,          
    palette="Set2"                   
)
           

plt.title("Distribution of Remote Work Types", fontsize=14)
plt.ylabel("Number of Job Postings")
plt.xlabel("Remote Type")
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig("figureswxw/remote_type_distribution.png", dpi=300)
plt.show()
```

![](figureswxw/remote_type_distribution.png){width=100% fig-align='center'}






##  Top 10 states by job postings
```{python}
#| echo: true
#| eval: true
#| code-fold: true
#| lable: "Top 10 states"
#| fig-align: center
#| fig-cap: "Remote type distribution"

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

if os.path.exists("data/lightcast_job_postings.csv"):
    df1 = pd.read_csv("data/lightcast_job_postings.csv")
    
    city_counts = df1["CITY_NAME"].dropna().value_counts().head(10)
    
    plt.figure(figsize=(10,5))
    sns.barplot(x=city_counts.index, y=city_counts.values, palette="Accent")
    plt.title("Top 10 Cities by Job Postings")
    plt.ylabel("Number of Job Postings")
    plt.xlabel("City")
    plt.xticks(rotation=30)
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.tight_layout()
    plt.savefig("figureswxw/top_cities_job_postings.png", dpi=300)
    plt.show()

else:
    print("Data file not found. Skipping data load and city barplot.")
```

