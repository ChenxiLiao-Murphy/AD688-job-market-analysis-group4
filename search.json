[
  {
    "objectID": "ml_analysis.html",
    "href": "ml_analysis.html",
    "title": "Modeling & Analysis",
    "section": "",
    "text": "This section presents our machine learning models to analyze geographic and remote work patterns in the 2024 U.S. job market. We apply both unsupervised and supervised learning methods to gain insights into how job locations and remote types impact salaries and job classifications."
  },
  {
    "objectID": "ml_analysis.html#supervised-learning-classification-predict-remote-type",
    "href": "ml_analysis.html#supervised-learning-classification-predict-remote-type",
    "title": "Modeling & Analysis",
    "section": "2.1 Supervised Learning: Classification – Predict Remote Type",
    "text": "2.1 Supervised Learning: Classification – Predict Remote Type\nTo understand what factors influence whether a job is remote, hybrid, or on-site, we trained a Random Forest Classifier using three features: STATE_NAME (location), SOC_2021_4 (job category), and MAX_YEARS_EXPERIENCE (seniority level).The model’s performance is summarized in a confusion matrix, which shows how accurately it distinguishes between different types of remote work arrangements.\n\n\nCode\n# Import libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Prepare dataset\ndf_class = df[['STATE_NAME', 'SOC_2021_4', 'MAX_YEARS_EXPERIENCE', 'REMOTE_TYPE_NAME']].dropna()\ndf_class_encoded = pd.get_dummies(df_class, columns=['STATE_NAME', 'SOC_2021_4'])\n\nX = df_class_encoded.drop('REMOTE_TYPE_NAME', axis=1)\ny = df_class['REMOTE_TYPE_NAME']\n\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Train classifier\nclf = RandomForestClassifier(random_state=42)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\n# Print performance\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n\n\n# Visualize confusion matrix\nplt.figure(figsize=(14,7))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix - Remote Work Type Classifier\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.tight_layout()\n\n# Save\nplt.savefig(\"figuresmurphy/confusion_matrix_remote_type.png\", dpi=300)\nplt.show()\n\n\n\n\n\n\n\nThe model accurately predicts class 3, but often misclassifies classes 0, 1, and 2 as 3, showing a bias toward the most common remote type. Job seekers should clearly state remote preferences, as nuanced roles may be missed by automated systems."
  },
  {
    "objectID": "ml_analysis.html#supervised-learning-regression-predict-salary",
    "href": "ml_analysis.html#supervised-learning-regression-predict-salary",
    "title": "Modeling & Analysis",
    "section": "2.2 Supervised Learning: Regression – Predict Salary",
    "text": "2.2 Supervised Learning: Regression – Predict Salary\nWe applied a Random Forest Regressor to estimate average salary using location, experience, remote type, and job category. The model captures complex patterns, highlighting how these factors shape compensation.\n\n\nCode\n# Step 1: Create AVERAGE_SALARY if not already in df\ndf['SALARY_FROM'] = pd.to_numeric(df['SALARY_FROM'], errors='coerce')\ndf['SALARY_TO'] = pd.to_numeric(df['SALARY_TO'], errors='coerce')\ndf['AVERAGE_SALARY'] = (df['SALARY_FROM'] + df['SALARY_TO']) / 2\n\n# Step 2: Drop rows with missing values in key columns\ndf_reg = df[['STATE_NAME', 'SOC_2021_4', 'REMOTE_TYPE_NAME', 'MAX_YEARS_EXPERIENCE', 'AVERAGE_SALARY']].dropna()\n\n# Step 3: One-hot encoding\ndf_reg_encoded = pd.get_dummies(df_reg, columns=['STATE_NAME', 'SOC_2021_4', 'REMOTE_TYPE_NAME'])\n\n# Step 4: Split X and y\nX = df_reg_encoded.drop('AVERAGE_SALARY', axis=1)\ny = df_reg_encoded['AVERAGE_SALARY']\n\n# Step 5: Train/test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Step 6: Train Random Forest Regressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Step 7: Predict\ny_pred = model.predict(X_test)\n\n# Step 8: Evaluate\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\nprint(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\nprint(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\nprint(\"R2 Score:\", r2_score(y_test, y_pred))\n\n\nplt.figure(figsize=(14, 8))\nplt.scatter(y_test, y_pred, alpha=0.5)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\nplt.xlabel(\"Actual Salary\")\nplt.ylabel(\"Predicted Salary\")\nplt.title(\"Actual vs Predicted Salary\")\nplt.grid(True, linestyle='--', linewidth=0.5, color='gray') \nplt.tight_layout()\nplt.savefig(\"figuresmurphy/actual_vs_predicted_salary.png\", dpi=300)\nplt.show()\n\n\n\n\n\n\n\nThe plot shows a strong alignment between predicted and actual salaries, with most points near the red dashed line—indicating good model performance. Some deviations, especially in higher salary ranges, reflect the difficulty of predicting roles with greater variability in seniority and industry."
  },
  {
    "objectID": "ml_analysis.html#which-states-are-more-inclined-to-offer-remotehybridonsite-jobs",
    "href": "ml_analysis.html#which-states-are-more-inclined-to-offer-remotehybridonsite-jobs",
    "title": "Modeling & Analysis",
    "section": "2.3 Which states are more inclined to offer Remote/Hybrid/Onsite jobs?",
    "text": "2.3 Which states are more inclined to offer Remote/Hybrid/Onsite jobs?\n\n\nCode\nimport matplotlib.pyplot as plt\n\ndf_geo = df[['STATE_NAME', 'REMOTE_TYPE_NAME']].dropna()\n\n\nstate_remote_counts = pd.crosstab(df_geo['STATE_NAME'], df_geo['REMOTE_TYPE_NAME'])\n\n# visualization\nstate_remote_counts.plot(kind='bar', stacked=True, figsize=(14,7))\nplt.title(\"Remote Work Type Distribution by State\")\nplt.xlabel(\"State\", fontsize=8)\nplt.xticks(rotation=45, ha='right')\nplt.grid(True, linestyle='--', linewidth=0.5, color='gray') \nplt.ylabel(\"Number of Job Postings\")\nplt.tight_layout()\n\nplt.savefig(\"figuresmurphy/remote_type_by_state.png\", dpi=300)\nplt.show()\n\n\n\n\n\nRemote Work Type by State\n\n\nThe bar chart shows that states like California, New York, and Texas have a high volume of job postings across all remote types. Remote roles are especially common in tech-focused states like California and Washington, while on-site jobs are more prevalent in states with stronger manufacturing industries."
  },
  {
    "objectID": "ml_analysis.html#choropleth-or-map-based-visualizations",
    "href": "ml_analysis.html#choropleth-or-map-based-visualizations",
    "title": "Modeling & Analysis",
    "section": "3.1 Choropleth or map-based visualizations",
    "text": "3.1 Choropleth or map-based visualizations\nWe used a choropleth map to visually represent the percentage of remote jobs per state. This spatial analysis can guide job seekers toward states with more flexible work environments.\n\n\nCode\nimport pandas as pd\nimport plotly.express as px\nimport pandas as pd\nimport plotly.express as px\n\n# 1. Create a full name -&gt; abbreviation mapping table\nstate_abbrev_map = {\n    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA',\n    'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA',\n    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA',\n    'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n    'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH',\n    'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC',\n    'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA',\n    'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN',\n    'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA',\n    'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'\n}\n\ndf_geo = df[['STATE_NAME', 'REMOTE_TYPE_NAME']].dropna()\n\n\n\n\nCode\ndf_geo = df[['STATE_NAME', 'REMOTE_TYPE_NAME']].dropna()\n\nremote_counts = df_geo[df_geo['REMOTE_TYPE_NAME'] == 'Remote'].groupby('STATE_NAME').size()\ntotal_counts = df_geo.groupby('STATE_NAME').size()\n\nremote_ratio_by_state = (remote_counts / total_counts).reset_index()\nremote_ratio_by_state.columns = ['STATE_NAME', 'REMOTE_RATIO']\n\nremote_ratio_by_state['STATE_ABBR'] = remote_ratio_by_state['STATE_NAME'].map(state_abbrev_map)\n\n\n\n\nCode\nimport geopandas as gpd\n\n# 1. 加载美国州边界 shapefile（事先下载过）\ngdf = gpd.read_file(\"shapefiles/cb_2021_us_state_20m.shp\")\n\n# 2. 去掉非主要州\ngdf = gdf[~gdf['STUSPS'].isin(['AS', 'GU', 'MP', 'PR', 'VI'])]\n\n# 3. 合并你的远程比例数据\ngdf = gdf.merge(remote_ratio_by_state, left_on='NAME', right_on='STATE_NAME')\n\n# 4. 画图\ncontiguous = gdf[~gdf['STUSPS'].isin(['AK', 'HI', 'PR'])]\n\nfig, ax = plt.subplots(1, 1, figsize=(14, 8))\ncontiguous.plot(\n    column='REMOTE_RATIO',\n    cmap='Blues',\n    linewidth=0.5,\n    ax=ax,\n    edgecolor='0.9',\n    legend=True,\n    legend_kwds={'label': \"Remote Job Ratio\", 'shrink': 0.5}\n)\n\nax.set_title('Remote Work Ratio by State (Contiguous U.S.)', fontsize=16, fontweight='bold')\nax.axis('off')\nplt.tight_layout()\nplt.savefig(\"figuresmurphy/us_remote_ratio_contiguous.png\", dpi=300)\nplt.show()\n\n\n\n\n\n\n\nThe map highlights that coastal and urban states like California, New York, and Massachusetts have more remote roles. In contrast, Midwest and Southern states show fewer remote postings, likely due to a stronger focus on in-person or manufacturing jobs."
  },
  {
    "objectID": "ml_analysis.html#logistic-regression-binary-classification-remote-vs-non-remote",
    "href": "ml_analysis.html#logistic-regression-binary-classification-remote-vs-non-remote",
    "title": "Modeling & Analysis",
    "section": "3.2 Logistic Regression: Binary Classification (Remote vs Non-Remote)",
    "text": "3.2 Logistic Regression: Binary Classification (Remote vs Non-Remote)\nTo identify what influences whether a job is remote, we used a logistic regression model. The confusion matrix below summarizes how well the model classifies remote and non-remote roles.\n\n\nCode\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# 1. Preprocessing\ndf_logistic = df[['STATE_NAME', 'MAX_YEARS_EXPERIENCE', 'AVERAGE_SALARY', 'REMOTE_TYPE_NAME']].dropna()\n\ndf_logistic['REMOTE_TYPE_CLEANED'] = df_logistic['REMOTE_TYPE_NAME'].map({\n    'Remote': 'Remote',\n    'Hybrid Remote': 'Hybrid',\n    'Not Remote': 'Onsite'\n}).fillna('Onsite')\n\n# Create binary classification target\ndf_logistic['IS_REMOTE'] = df_logistic['REMOTE_TYPE_CLEANED'].apply(lambda x: 1 if x == 'Remote' else 0)\n\n# 2. One-hot encode state name\ndf_encoded = pd.get_dummies(df_logistic, columns=['STATE_NAME'], drop_first=True)\n\n# 3. Split data\nX = df_encoded.drop(['IS_REMOTE', 'REMOTE_TYPE_NAME', 'REMOTE_TYPE_CLEANED'], axis=1)\ny = df_encoded['IS_REMOTE']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# 4. Train model\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n# 5.  Evaluation\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n\n# 6. Visualize confusion matrix\nplt.figure(figsize=(10,8))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='YlGnBu')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.tight_layout()\nplt.savefig(\"figuresmurphy/logistic_confusion_matrix.png\", dpi=300)\nplt.show()\n\n\n\n\n\n\n\nThe model accurately distinguishes remote from non-remote jobs, performing better on non-remote roles. Some misclassifications remain, so job seekers in flexible roles should clearly state their work preferences."
  },
  {
    "objectID": "ml_analysis.html#linear-regression",
    "href": "ml_analysis.html#linear-regression",
    "title": "Modeling & Analysis",
    "section": "4.1 Linear Regression",
    "text": "4.1 Linear Regression\nWe also used a linear regression model to predict average salary based on location, experience, and remote type. The actual vs. predicted plot and residuals histogram below show the model’s performance.\n\n\nCode\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\n\n# 1. Preprocessing\ndf_reg = df[['STATE_NAME', 'MAX_YEARS_EXPERIENCE', 'REMOTE_TYPE_NAME', 'AVERAGE_SALARY']].dropna()\ndf_reg = df_reg[df_reg['AVERAGE_SALARY'] &lt; 300000]  #  Remove salary outliers\n\ndf_reg['REMOTE_TYPE_CLEANED'] = df_reg['REMOTE_TYPE_NAME'].map({\n    'Remote': 'Remote',\n    'Hybrid Remote': 'Hybrid',\n    'Not Remote': 'Onsite'\n}).fillna('Onsite')\n\n# 2. One-hot encode\ndf_reg_encoded = pd.get_dummies(df_reg, columns=['STATE_NAME', 'REMOTE_TYPE_CLEANED'], drop_first=True)\n\n# 3. Split data\nX = df_reg_encoded.drop(['REMOTE_TYPE_NAME', 'AVERAGE_SALARY'], axis=1)\ny = df_reg_encoded['AVERAGE_SALARY']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# 4.Train model\nreg_model = LinearRegression()\nreg_model.fit(X_train, y_train)\ny_pred = reg_model.predict(X_test)\n\n# 5. Evaluation\nprint(\"MSE:\", mean_squared_error(y_test, y_pred))\nprint(\"R-squared:\", r2_score(y_test, y_pred))\n\n# 6. Scatterplot of actual vs predicted\nplt.figure(figsize=(14, 7))\nplt.scatter(y_test, y_pred, alpha=0.5)\nplt.xlabel(\"Actual Salary\")\nplt.ylabel(\"Predicted Salary\")\nplt.title(\" Actual vs. Predicted Salary\")\nplt.grid(True, linestyle='--', linewidth=0.5, color='gray')\nplt.tight_layout()\nplt.savefig(\"figuresmurphy/regression_actual_vs_predicted.png\", dpi=300)\nplt.show()\n\n\n\n\n\n\n\nThe plot shows a clear linear trend but with greater dispersion compared to the random forest model, indicating that linear regression struggles to capture more complex salary patterns.\n\n\nCode\n# 7. Residuals histogram\nresiduals = y_test - y_pred\nplt.figure(figsize=(10, 6))\nplt.hist(residuals, bins=30, color='orange', edgecolor='black')\nplt.title(\"Residuals Histogram\")\nplt.xlabel(\"Residuals\")\nplt.ylabel(\"Frequency\")\nplt.tight_layout()\nplt.grid(True, linestyle='--', linewidth=0.5, color='gray')\nplt.savefig(\"figuresmurphy/regression_residuals.png\", dpi=300)\nplt.show()\n\n\n\n\n\n\n\nThe residuals histogram is roughly normal and centered around zero, suggesting no major bias. However, the spread shows that predictions can vary by several thousand dollars based on the input features."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AD688 Summer25 Group Project - Job Market Analysis - Group 4",
    "section": "",
    "text": "Welcome\nThis project analyzes recent trends in job market geography, remote work, and AI-related employment across the United States.\nIt is part of the AD688 Summer 2025 Group Project conducted by Group 4.\n\n\nTable of Contents\nExplore the following sections:\n\nAbout the Project\nIntroduction & Motivation\nData Cleaning & EDA\nEnhanced EDA (Geographic Focus)\nSkill Gap Analysis\nNLP Methods\nMachine Learning Analysis"
  },
  {
    "objectID": "skill_gap_analysis.html",
    "href": "skill_gap_analysis.html",
    "title": "Skill Gap Analysis",
    "section": "",
    "text": "This section presents the skill gap analysis between job requirements and available workforce skills."
  },
  {
    "objectID": "skill_gap_analysis.html#team-members-current-skill-levels",
    "href": "skill_gap_analysis.html#team-members-current-skill-levels",
    "title": "Skill Gap Analysis",
    "section": "1.1 Team Members’ Current Skill Levels",
    "text": "1.1 Team Members’ Current Skill Levels\n\nskills_data = {\n    \"Name\": [\"Eugenia\", \"Chenxi\", \"Xiangwen\"],\n    \"Python\": [3, 3, 5],\n    \"SQL\": [4, 2, 3],\n    \"Machine Learning\": [1, 2, 4],\n    \"Cloud Computing\": [3, 1, 2],\n    \"AWS\": [2, 4, 3],\n    \"Docker\": [2,2,2]\n}\n\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills"
  },
  {
    "objectID": "skill_gap_analysis.html#current-skill-heatmap",
    "href": "skill_gap_analysis.html#current-skill-heatmap",
    "title": "Skill Gap Analysis",
    "section": "1.2 Current Skill Heatmap",
    "text": "1.2 Current Skill Heatmap\n\n\nCode\nplt.figure(figsize=(10, 6))\nsns.heatmap(df_skills, annot=True, cmap=\"coolwarm\", linewidths=0.5)\nplt.xlabel(\"Technical Skills\", fontsize=14)       \nplt.ylabel(\"Team Members\", fontsize=14) \nplt.xticks(rotation=30)  \nplt.title(\"Team Skill Levels Heatmap\")\nplt.tight_layout()\nplt.savefig(\"figurestyj/team_skill_heatmap.png\", dpi=300,  bbox_inches='tight')\nplt.show()"
  },
  {
    "objectID": "skill_gap_analysis.html#personalized-upskilling-recommendations",
    "href": "skill_gap_analysis.html#personalized-upskilling-recommendations",
    "title": "Skill Gap Analysis",
    "section": "1.3 Personalized Upskilling Recommendations",
    "text": "1.3 Personalized Upskilling Recommendations\nTo close the observed skill gaps, we provide the following individualized upskilling plans:\nEugenia is advised to focus on Machine Learning and AWS to better align with industry expectations.\nChenxi would benefit from strengthening her Cloud Computing and Python skills.\nXiangwen is recommended to enhance his proficiency in Docker and Cloud-related technologies.\nThese suggestions are based on both internal team comparisons and external job market demands, and they aim to improve overall team balance and job readiness."
  },
  {
    "objectID": "skill_gap_analysis.html#compute-average-team-skills-vs-industry-expectations",
    "href": "skill_gap_analysis.html#compute-average-team-skills-vs-industry-expectations",
    "title": "Skill Gap Analysis",
    "section": "2.1 Compute Average Team Skills vs Industry Expectations",
    "text": "2.1 Compute Average Team Skills vs Industry Expectations\n\n\nCode\ntop_skills = [\"Python\", \"SQL\", \"Machine Learning\", \"Cloud Computing\", \"Docker\", \"AWS\"]\njob_skill_counts = Counter(top_skills)\n\nfor skill in top_skills:\n    if skill not in df_skills.columns:\n        df_skills[skill] = 0  # Assume no knowledge in missing skills\n\ndf_skills\n\n\nos.makedirs(\"figurestyj\", exist_ok=True)\n\nteam_avg_skills = df_skills.mean()\n\nskills_to_plot = []\nfor skill in top_skills:\n    score = team_avg_skills[skill] if skill in team_avg_skills else 0\n    skills_to_plot.append(score)\n\nplt.figure(figsize=(10, 5))\nplt.bar(top_skills, skills_to_plot, color=\"skyblue\")\nplt.title(\"Average Team Skill Levels vs Top Skills\")\nplt.xlabel(\"Technical Skills\", fontsize=14)  \nplt.ylabel(\"Average Score\",fontsize=14 )\nplt.xticks(rotation=45)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(\"figurestyj/team_vs_industry_skills.png\", dpi=300,  bbox_inches='tight')\nplt.show()"
  },
  {
    "objectID": "nlp_methods.html",
    "href": "nlp_methods.html",
    "title": "NLP Methods",
    "section": "",
    "text": "This section uses natural language processing (NLP) to extract insights from job descriptions in the dataset, focusing on the most frequent skills and terms mentioned. We apply TF-IDF to identify distinguishing keywords, and generate a word cloud for intuitive visualization.\n\n1 Load and Preprocess Text Data\n\n\nCode\nimport pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n\nCode\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\", encoding=\"utf-8\", on_bad_lines='skip')\n\n\n\n\nCode\njob_desc = df[\"BODY\"].dropna().astype(str)\n\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'\\d+', '', text)\n    text = re.sub(r'[^\\w\\s]', '', text)\n    return text\n\njob_desc_clean = job_desc.apply(clean_text)\n\n\n\n\n2 TF-IDF Analysis: Top Keywords\n\n\nCode\ntfidf = TfidfVectorizer(max_features=30, stop_words=\"english\")\ntfidf_matrix = tfidf.fit_transform(job_desc_clean)\n\nfeature_names = tfidf.get_feature_names_out()\nscores = tfidf_matrix.sum(axis=0).A1\n\ntfidf_df = pd.DataFrame({\"Term\": feature_names, \"Score\": scores})\ntfidf_df = tfidf_df.sort_values(by=\"Score\", ascending=False)\ntfidf_df.head(10)\n\n\n\n\nCode\nplt.figure(figsize=(14, 7))\nsns.barplot(data=tfidf_df.head(15), x=\"Score\", y=\"Term\", palette=\"viridis\")\nplt.title(\"Top TF-IDF Keywords in Job Descriptions\")\nplt.grid(axis='x', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(\"figurestyj/tfidf_keywords.png\", dpi=300,  bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\n\n3 Word Cloud Visualization\n\n\nCode\nfrom wordcloud import WordCloud\n\ntext_blob = \" \".join(job_desc_clean.tolist())\n\nwordcloud = WordCloud(width=1000, height=400, background_color=\"white\", max_words=100).generate(text_blob)\n\n\n\n\nCode\nplt.figure(figsize=(14, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title(\"Word Cloud of Job Description Terms\")\nplt.tight_layout()\nplt.savefig(\"figurestyj/jobdesc_wordcloud.png\", dpi=300)\nplt.show()\n\n\n\nThe results from the TF-IDF analysis reveal that the most distinctive keywords across job postings are “data”, “experience”, “business”, and “job”. These terms highlight the prevalence of data-centric roles in the current job market and underscore the significance of prior professional experience as a hiring criterion. Other frequently weighted terms include “skills”, “management”, and “team”, which indicate that employers are seeking candidates who possess both technical competencies and the ability to collaborate effectively within organizational structures.\nIn addition to the TF-IDF results, the word cloud visualization further enriches our understanding by emphasizing the recurring presence of phrases such as “bachelors degree”, “data analyst”, “support”, and “ability”. This aligns with expectations that many job postings include educational qualifications and role-specific technical terms. Moreover, the word cloud captures compliance-related language such as “gender identity”, “sexual orientation”, and “national origin”. These terms are commonly found in equal opportunity employment disclosures and reflect widespread adherence to diversity and inclusion standards in job advertisements.\nCollectively, the TF-IDF scores and the word cloud suggest several dominant themes within job descriptions. First, there is a consistent emphasis on technical qualifications, including skills in data analysis, cloud platforms, and tools such as Python and SAP. Second, postings frequently reference soft skills such as management, communication, and teamwork. Third, many job ads incorporate legal or standardized phrasing associated with hiring equity and regulatory compliance. Lastly, there is a strong focus on candidates’ educational background and accumulated experience.\nThese findings provide actionable guidance for job seekers, especially those pursuing roles in AI, tech, or data-related fields. Individuals are encouraged to showcase both technical expertise and interpersonal effectiveness in their resumes. Additionally, familiarity with standardized workplace language and professional communication expectations may enhance alignment with employer requirements."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 About This Project\nThis project explores the evolving landscape of the U.S. job market through the lens of geographic distribution and remote work trends. Leveraging Lightcast’s extensive job postings dataset, we analyze how employment patterns differ across regions, industries, and occupations, with a focus on:\n\nThe rise of AI-related job opportunities versus non-AI roles;\nRegional shifts in job availability and growth across states and metropolitan areas;\nThe impact and distribution of remote, hybrid, and onsite work models;\nEmerging career paths in both urban and rural labor markets.\n\nBy combining Exploratory Data Analysis (EDA), Spark SQL, Natural Language Processing (NLP), and Machine Learning (including PCA and clustering), our project aims to uncover hidden structures in job posting data and generate actionable insights for students, job seekers, and policymakers navigating the post-pandemic workforce.\nThis project was developed as part of AD688 Web Analytics and Big Data Tools at Boston University, integrating large-scale data processing and visualization techniques to inform real-world workforce decisions.\n\n\n2 Team Members\n\nChenxi(Murphy) Liao murphyy@bu.edu\nYijiun(Eugenia) Tseng yijiun@bu.edu\nXiangwen(Rosa) Wang wxwrosa@bu.edu"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "The rise of remote work, accelerated by the COVID-19 pandemic, has significantly reshaped the labour market and job geography in the United States and beyond. This shift has introduced new dynamics in how and where work is performed, with important implications for job accessibility, regional economies, and employment equity ( Hansen et al. (2023)). Geographic patterns now play a key role in determining access to job opportunities. Remote work adoption has been uneven across industries and cities, presenting both challenges and opportunities for regional development.\nAt the same time, the growth of artificial intelligence (AI) is changing the types of jobs that are available. AI-related jobs may either cluster in a few established tech hubs, such as Boston, New York City, and Los Angeles, or spread more evenly across regions, influencing regional economic balance (Hsu & Tambe (2024)). These trends could either reinforce or reduce geographic inequalities. Understanding these shifts is essential, as they affect job seekers’ decisions, employer location strategies, and regional economic resilience.\nThe year 2024 represents a critical moment in these developments. Hybrid work has become more common, and some companies are encouraging employees to return to the office (Tahlyan et al. (2024)). At the same time, new tech hubs are emerging outside of traditional centers like Silicon Valley. These emerging hubs may offer fresh opportunities for regions that have not been tech leaders in the past (Tan et al. (2023)). Remote work trends and the decentralisation of AI-related and other high-skill jobs could reshape the distribution of employment and economic activity.\nThis project aims to analyze geographic variations in AI and non-AI job growth, the prevalence of remote work across locations, and the evolving role of traditional and emerging tech hubs in the 2024 labor market. We expect to identify leading metropolitan statistical areas (MSAs) for both AI and non-AI jobs, assess whether remote work opportunities are continuing to expand or plateau, and determine if job growth is becoming more geographically dispersed or remains concentrated. These findings will help job seekers and employers make informed decisions on where to focus their efforts, based on the changing interplay of AI adoption, remote work, and regional economic trends (Zheng et al. (2024)).\n\n\n\n\nReferences\n\nHansen, S., Lambert, P., Bloom, N., Davis, S. J., Sadun, R., & Taska, B. (2023). Remote work across jobs, companies, and space. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.4380734\n\n\nHsu, D. H., & Tambe, P. (2024). Remote work and job applicant diversity: Evidence from technology startups. Management Science. https://doi.org/10.1287/mnsc.2022.03391\n\n\nTahlyan, D., Mahmassani, H., Stathopoulos, A., Said, M., Shaheen, S. A., Walker, J., & Johnson, B. (2024). In-person, hybrid or remote? Employers’ perspectives on the future of work post-pandemic. Transportation Research Part A: Policy and Practice. https://doi.org/10.1016/j.tra.2024.104273\n\n\nTan, S., Fang, K., & Lester, T. (2023). Post-pandemic travel patterns of remote tech workers. Transportation Research Interdisciplinary Perspectives. https://doi.org/10.1016/j.trip.2023.100804\n\n\nZheng, Y., Wang, S., Liu, L., Aloisi, J., & Zhao, J. (2024). Impacts of remote work on vehicle miles traveled and transit ridership in the USA. Nature Cities. https://doi.org/10.1038/s44284-024-00057-1"
  },
  {
    "objectID": "data_cleaning_eda.html",
    "href": "data_cleaning_eda.html",
    "title": "Data Cleaning & EDA",
    "section": "",
    "text": "# Define columns that are irrelevant or redundant for our analysis\ncolumns_to_drop = [\n    # Tracking and metadata\n    \"ID\", \"LAST_UPDATED_DATE\", \"LAST_UPDATED_TIMESTAMP\", \"DUPLICATES\",\n    \"URL\", \"ACTIVE_URLS\", \"ACTIVE_SOURCES_INFO\", \"SOURCE_TYPES\", \"SOURCES\",\n\n    # Company raw info\n    \"COMPANY_RAW\", \"COMPANY_IS_STAFFING\",\n\n    # Raw or text-heavy fields\n    \"TITLE_RAW\", \"BODY\",\n\n    # Modeled / derived fields\n    \"MODELED_EXPIRED\", \"MODELED_DURATION\",\n\n    # Educational levels (redundant versions)\n    \"EDUCATION_LEVELS\", \"EDUCATION_LEVELS_NAME\",\n    \"MIN_EDULEVELS\", \"MIN_EDULEVELS_NAME\", \"MAX_EDULEVELS\",\n\n    # Redundant NAICS / SOC codes\n    \"NAICS_2022_2\", \"NAICS_2022_2_NAME\",\n    \"NAICS_2022_3\", \"NAICS_2022_3_NAME\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\n\n# Drop columns, ignore if a column is missing\ndf1.drop(columns=columns_to_drop, inplace=True, errors=\"ignore\")\n\n# Display the first few rows to confirm\ndf1.head()\n\n\n\n\n\n\nCode\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nos.makedirs(\"figureswxw\", exist_ok=True)\n\n\n\n\nCode\nimport missingno as msno\nimport matplotlib.pyplot as plt\nmsno.heatmap(df1)\n\nplt.title(\"Missing Values Heatmap\")\nplt.tight_layout()\nplt.savefig(\"figureswxw/missing_values_heatmap.png\", dpi=300,  bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\n\nCode\n# Drop columns with &gt;50% missing values\ndf1.dropna(axis=1, thresh=len(df1) * 0.5, inplace=True)\n\n\nif \"SALARY\" in df1.columns:\n    df1[\"SALARY\"] = df1[\"SALARY\"].fillna(df1[\"SALARY\"].median())\n\n    df1[\"DURATION\"] = df1[\"DURATION\"].fillna(df1[\"DURATION\"].median())\n\ncategorical_columns = [\"REMOTE_TYPE_NAME\", \"COMPANY_NAME\", \"MAX_EDULEVELS_NAME\"]\n\nfor col in categorical_columns:\n    if col in df1.columns:\n        df1[col] = df1[col].fillna(\"Unknown\")\n\n\ndf1.info()\n\n\n\n\n\n\ndf1.drop_duplicates(subset=[\"TITLE_CLEAN\", \"COMPANY_NAME\", \"CITY_NAME\", \"POSTED\"], inplace=True)\n\ndf1[\"REMOTE_TYPE_NAME\"].value_counts(dropna=False)\ndf1[\"EMPLOYMENT_TYPE_NAME\"].value_counts(dropna=False)\n\n\n\nCode\n#improve\n\ndf1[\"EMPLOYMENT_TYPE_NAME\"] = df1[\"EMPLOYMENT_TYPE_NAME\"].replace({\n    \"Part-time (â‰¤ 32 hours)\": \"Part-time (≤ 32 hours)\",\n    \"Part-time / full-time\": \"Part-time / Full-time\"\n})\ndf1[\"EMPLOYMENT_TYPE_NAME\"] = df1[\"EMPLOYMENT_TYPE_NAME\"].fillna(\"Unknown\")\ndf1[\"EMPLOYMENT_TYPE_NAME\"].value_counts()"
  },
  {
    "objectID": "data_cleaning_eda.html#dropping-unnecessary-columns",
    "href": "data_cleaning_eda.html#dropping-unnecessary-columns",
    "title": "Data Cleaning & EDA",
    "section": "",
    "text": "# Define columns that are irrelevant or redundant for our analysis\ncolumns_to_drop = [\n    # Tracking and metadata\n    \"ID\", \"LAST_UPDATED_DATE\", \"LAST_UPDATED_TIMESTAMP\", \"DUPLICATES\",\n    \"URL\", \"ACTIVE_URLS\", \"ACTIVE_SOURCES_INFO\", \"SOURCE_TYPES\", \"SOURCES\",\n\n    # Company raw info\n    \"COMPANY_RAW\", \"COMPANY_IS_STAFFING\",\n\n    # Raw or text-heavy fields\n    \"TITLE_RAW\", \"BODY\",\n\n    # Modeled / derived fields\n    \"MODELED_EXPIRED\", \"MODELED_DURATION\",\n\n    # Educational levels (redundant versions)\n    \"EDUCATION_LEVELS\", \"EDUCATION_LEVELS_NAME\",\n    \"MIN_EDULEVELS\", \"MIN_EDULEVELS_NAME\", \"MAX_EDULEVELS\",\n\n    # Redundant NAICS / SOC codes\n    \"NAICS_2022_2\", \"NAICS_2022_2_NAME\",\n    \"NAICS_2022_3\", \"NAICS_2022_3_NAME\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\n\n# Drop columns, ignore if a column is missing\ndf1.drop(columns=columns_to_drop, inplace=True, errors=\"ignore\")\n\n# Display the first few rows to confirm\ndf1.head()"
  },
  {
    "objectID": "data_cleaning_eda.html#handling-missing-values",
    "href": "data_cleaning_eda.html#handling-missing-values",
    "title": "Data Cleaning & EDA",
    "section": "",
    "text": "Code\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nos.makedirs(\"figureswxw\", exist_ok=True)\n\n\n\n\nCode\nimport missingno as msno\nimport matplotlib.pyplot as plt\nmsno.heatmap(df1)\n\nplt.title(\"Missing Values Heatmap\")\nplt.tight_layout()\nplt.savefig(\"figureswxw/missing_values_heatmap.png\", dpi=300,  bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\n\nCode\n# Drop columns with &gt;50% missing values\ndf1.dropna(axis=1, thresh=len(df1) * 0.5, inplace=True)\n\n\nif \"SALARY\" in df1.columns:\n    df1[\"SALARY\"] = df1[\"SALARY\"].fillna(df1[\"SALARY\"].median())\n\n    df1[\"DURATION\"] = df1[\"DURATION\"].fillna(df1[\"DURATION\"].median())\n\ncategorical_columns = [\"REMOTE_TYPE_NAME\", \"COMPANY_NAME\", \"MAX_EDULEVELS_NAME\"]\n\nfor col in categorical_columns:\n    if col in df1.columns:\n        df1[col] = df1[col].fillna(\"Unknown\")\n\n\ndf1.info()"
  },
  {
    "objectID": "data_cleaning_eda.html#remove-duplicates",
    "href": "data_cleaning_eda.html#remove-duplicates",
    "title": "Data Cleaning & EDA",
    "section": "",
    "text": "df1.drop_duplicates(subset=[\"TITLE_CLEAN\", \"COMPANY_NAME\", \"CITY_NAME\", \"POSTED\"], inplace=True)\n\ndf1[\"REMOTE_TYPE_NAME\"].value_counts(dropna=False)\ndf1[\"EMPLOYMENT_TYPE_NAME\"].value_counts(dropna=False)\n\n\n\nCode\n#improve\n\ndf1[\"EMPLOYMENT_TYPE_NAME\"] = df1[\"EMPLOYMENT_TYPE_NAME\"].replace({\n    \"Part-time (â‰¤ 32 hours)\": \"Part-time (≤ 32 hours)\",\n    \"Part-time / full-time\": \"Part-time / Full-time\"\n})\ndf1[\"EMPLOYMENT_TYPE_NAME\"] = df1[\"EMPLOYMENT_TYPE_NAME\"].fillna(\"Unknown\")\ndf1[\"EMPLOYMENT_TYPE_NAME\"].value_counts()"
  },
  {
    "objectID": "data_cleaning_eda.html#remote-type-distribution",
    "href": "data_cleaning_eda.html#remote-type-distribution",
    "title": "Data Cleaning & EDA",
    "section": "2.1 Remote Type distribution",
    "text": "2.1 Remote Type distribution\n\n\nCode\nremote_counts = df1[\"REMOTE_TYPE_NAME\"].value_counts()\n\nplt.figure(figsize=(10,6))\nsns.barplot(\n    x=remote_counts.index, \n    y=remote_counts.values, \n    palette=\"Set2\"\n)\nplt.title(\"Remote Type Distribution\")\nplt.ylabel(\"Number of Job Postings\")\nplt.xlabel(\"Remote Type\")\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(\"figureswxw/remote_type_distribution.png\", dpi=300,  bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\n\nCode\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf1[\"IS_AI\"] = df1[\"NAICS_2022_6_NAME\"].fillna(\"\").str.contains(\"AI|Artificial Intelligence\", case=False) | \\\n               df1[\"LOT_OCCUPATION\"].fillna(\"\").str.contains(\"AI|Artificial Intelligence\", case=False)\n\ndf1[\"IS_AI\"] = df1[\"IS_AI\"].map({True: \"AI\", False: \"Non-AI\"})"
  },
  {
    "objectID": "data_cleaning_eda.html#top-10-states-ai-vs-non-ai-job-postings",
    "href": "data_cleaning_eda.html#top-10-states-ai-vs-non-ai-job-postings",
    "title": "Data Cleaning & EDA",
    "section": "2.2 Top 10 states : AI vs Non-AI Job Postings",
    "text": "2.2 Top 10 states : AI vs Non-AI Job Postings\n\n\nCode\ntop_states = df1[\"STATE_NAME\"].value_counts().head(10).index\ndf_top_states = df1[df1[\"STATE_NAME\"].isin(top_states)]\n\npivot_states = df_top_states.groupby([\"STATE_NAME\", \"IS_AI\"]).size().unstack(fill_value=0)\n\npivot_states.plot(kind=\"bar\", stacked=True, figsize=(12,6), colormap=\"Set3\")\nplt.title(\"Top 10 States: AI vs Non-AI Job Postings\")\nplt.ylabel(\"Number of Job Postings\")\nplt.xlabel(\"State\")\nplt.xticks(rotation=30)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(\"figureswxw/top_states_ai_nonai.png\", dpi=300,  bbox_inches='tight')\nplt.show()"
  },
  {
    "objectID": "data_cleaning_eda.html#top-10-cities-ai-vs-non-ai-job-postings",
    "href": "data_cleaning_eda.html#top-10-cities-ai-vs-non-ai-job-postings",
    "title": "Data Cleaning & EDA",
    "section": "2.3 Top 10 cities: AI vs Non-AI Job Postings",
    "text": "2.3 Top 10 cities: AI vs Non-AI Job Postings\n\n\nCode\ntop_cities = df1[\"CITY_NAME\"].value_counts().head(10).index\ndf_top_cities = df1[df1[\"CITY_NAME\"].isin(top_cities)]\n\npivot_cities = df_top_cities.groupby([\"CITY_NAME\", \"IS_AI\"]).size().unstack(fill_value=0)\n\npivot_cities.plot(kind=\"bar\", stacked=True, figsize=(12,6), colormap=\"Set1\")\nplt.title(\"Top 10 Cities: AI vs Non-AI Job Postings\")\nplt.ylabel(\"Number of Job Postings\")\nplt.xlabel(\"City\")\nplt.xticks(rotation=30)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(\"figureswxw/top_cities_ai_nonai.png\", dpi=300)\nplt.show()"
  },
  {
    "objectID": "data_cleaning_eda.html#time-trend-of-remote-work-types",
    "href": "data_cleaning_eda.html#time-trend-of-remote-work-types",
    "title": "Data Cleaning & EDA",
    "section": "2.4 Time Trend of Remote Work Types",
    "text": "2.4 Time Trend of Remote Work Types\n\n\nCode\nif \"POSTED\" in df1.columns:\n    df1[\"POSTED_DATE\"] = pd.to_datetime(df1[\"POSTED\"], errors='coerce')\n    df1 = df1.dropna(subset=[\"POSTED_DATE\"])\n    df1[\"POSTED_MONTH\"] = df1[\"POSTED_DATE\"].dt.to_period(\"M\")\n    \n    trend = df1.groupby([\"POSTED_MONTH\", \"REMOTE_TYPE_NAME\"]).size().unstack(fill_value=0)\n    \n    trend.plot(figsize=(14,7))\n    plt.title(\"Remote Work Trends Over Time\", fontsize=14)\n    plt.ylabel(\"Number of Job Postings\")\n    plt.xlabel(\"Month\")\n    plt.grid(axis='y', linestyle='--', alpha=0.7)\n    plt.tight_layout()\n    plt.savefig(\"figureswxw/remote_trend_over_time.png\", dpi=300,  bbox_inches='tight')\n    plt.show()\nelse:\n    print(\"POSTED column not found in dataset.\")"
  },
  {
    "objectID": "data_cleaning_eda.html#tech-hubs-vs-other-locations-hiring-trends",
    "href": "data_cleaning_eda.html#tech-hubs-vs-other-locations-hiring-trends",
    "title": "Data Cleaning & EDA",
    "section": "2.5 Tech Hubs vs Other Locations Hiring Trends",
    "text": "2.5 Tech Hubs vs Other Locations Hiring Trends\n\n\nCode\ndf1[\"IS_HUB\"] = df1[\"CITY_NAME\"].apply(lambda x: \"Hub\" if x in [\"San Francisco\", \"Austin\", \"Boston\"] else \"Other\")\n\npivot_hub = df1.groupby([\"POSTED_MONTH\", \"IS_HUB\"]).size().unstack(fill_value=0)\n\npivot_hub.plot(figsize=(14,7))\nplt.title(\"Hiring Trends: Tech Hubs vs Other Locations\")\nplt.ylabel(\"Number of Job Postings\")\nplt.xlabel(\"Month\")\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(\"figureswxw/techhub_vs_other_trend.png\", dpi=300, bbox_inches='tight')\nplt.show()"
  },
  {
    "objectID": "data_cleaning_eda.html#remote-job-trend-by-industry",
    "href": "data_cleaning_eda.html#remote-job-trend-by-industry",
    "title": "Data Cleaning & EDA",
    "section": "2.6 Remote Job Trend by Industry",
    "text": "2.6 Remote Job Trend by Industry\n\n\nCode\ntop_industries = (\n    df1.groupby(\"NAICS_2022_6_NAME\").size()\n    .sort_values(ascending=False)\n    .head(10)\n    .index\n)\n\n\ndf_top_ind = df1[df1[\"NAICS_2022_6_NAME\"].isin(top_industries)]\n\n\ndf_top_ind[\"POSTED_DATE\"] = pd.to_datetime(df_top_ind[\"POSTED\"], errors='coerce')\ndf_top_ind = df_top_ind.dropna(subset=[\"POSTED_DATE\"])\ndf_top_ind[\"POSTED_MONTH\"] = df_top_ind[\"POSTED_DATE\"].dt.to_period(\"M\")\n\n\npivot = df_top_ind.groupby([\"POSTED_MONTH\", \"NAICS_2022_6_NAME\"]).size().unstack(fill_value=0)\n\npivot.plot(figsize=(14,7))\nplt.title(\"Remote Job Trends by Top 5 Industries Over Time\", fontsize=14)\nplt.ylabel(\"Number of Job Postings\")\nplt.xlabel(\"Month\")\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.legend(\n    title=\"NAICS_2022_6_NAME\",\n    loc='upper center',\n    bbox_to_anchor=(0.5, -0.15),  \n    ncol=2,                       \n    frameon=False\n)\nplt.tight_layout()\nplt.savefig(\"figureswxw/remote_trend_top5_industry.png\", dpi=30,  bbox_inches='tight')\nplt.show()"
  },
  {
    "objectID": "data_cleaning_eda.html#urbanrural-region-ai-vs-non-ai-job-postings",
    "href": "data_cleaning_eda.html#urbanrural-region-ai-vs-non-ai-job-postings",
    "title": "Data Cleaning & EDA",
    "section": "2.7 Urban/Rural Region: AI vs Non-AI Job Postings",
    "text": "2.7 Urban/Rural Region: AI vs Non-AI Job Postings\n\n\nCode\nurban_cities = [\n    \"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"San Francisco\",\n    \"Austin\", \"Boston\", \"Dallas\", \"Seattle\", \"Washington\", \"Atlanta\"\n]\n\ndf1[\"CITY_NAME_CLEAN\"] = df1[\"CITY_NAME\"].str.split(\",\").str[0].str.strip().str.title()\n\ndf1[\"Urban_Rural\"] = df1[\"CITY_NAME_CLEAN\"].apply(\n    lambda x: \"Urban\" if x in urban_cities else \"Rural\"\n)\n\nprint(df1[\"Urban_Rural\"].value_counts())\n\n\n\n2.7.1 Stacked Bar Chart\n\n\nCode\nif {\"Urban_Rural\", \"IS_AI\"}.issubset(df1.columns):\n    pivot_urban = df1.groupby([\"Urban_Rural\", \"IS_AI\"]).size().unstack(fill_value=0)\n\n    ax = pivot_urban.plot(\n        kind=\"bar\",\n        stacked=True,\n        figsize=(10, 6),\n        color=[\"#ff9999\", \"#66b3ff\"],\n        edgecolor=\"black\"\n    )\n    ax.set_title(\"Urban and Rural Regions: AI vs Non-AI Job Postings\", fontsize=14)\n    ax.set_ylabel(\"Number of Job Postings\")\n    ax.set_xlabel(\"Region Type\")\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n    ax.grid(axis='y', linestyle='--', alpha=0.7)\n\n    plt.tight_layout()\n    plt.savefig(\"figureswxw/urban_rural_ai_nonai_bar.png\", dpi=300,  bbox_inches='tight')\n    plt.show()\n\nelse:\n    print(\"Required columns are missing. Please check your dataset.\")\n\n\n\n\n\n\n\n\n\n2.7.2 Pie Chart\n\n\nCode\nimport matplotlib.pyplot as plt\n\nif {\"Urban_Rural\", \"IS_AI\"}.issubset(df1.columns):\n    pivot_urban = df1.groupby([\"Urban_Rural\", \"IS_AI\"]).size().unstack(fill_value=0)\n\n    fig, axes = plt.subplots(1, 2, figsize=(10, 6))  \n\n    for ax, region in zip(axes, [\"Urban\", \"Rural\"]):\n        data = pivot_urban.loc[region]\n        ax.pie(\n            data,\n            labels=data.index,\n            autopct='%1.1f%%',\n            startangle=90,\n            colors=[\"#ff9999\", \"#66b3ff\"],\n            wedgeprops={'edgecolor': 'black'}\n        )\n        ax.set_title(f\"{region} - AI vs Non-AI\")\n\n    plt.tight_layout()\n    plt.savefig(\"figureswxw/urban_rural_ai_nonai_pie_combined.png\", dpi=300,  bbox_inches='tight')\n    plt.show()\n\nelse:\n    print(\"Required columns are missing. Please check your dataset.\")"
  },
  {
    "objectID": "eda_enhance.html",
    "href": "eda_enhance.html",
    "title": "Extended EDA: Geographic Distribution",
    "section": "",
    "text": "This section presents an enhanced exploratory data analysis of job postings in the United States, with particular attention to remote work types and geographic patterns across industries, states, and cities. The objective is to examine how the distribution of remote, hybrid, and onsite jobs differs across regions, and how industry-specific trends reflect broader labor market shifts. Through this analysis, we aim to capture regional disparities, identify emerging hiring hubs, and understand how remote work adoption is reshaping spatial dynamics in the 2024 job market.\n\n1 Job Distribution by Industry (NAICS Level 2)\n\n\nCode\nwrapped_labels = ['\\n'.join(textwrap.wrap(label, width=10)) for label in industry_counts[\"Industry\"]]\n\nplt.figure(figsize=(18, 12))\nax = sns.barplot(data=industry_counts, x=\"Industry\", y=\"Job_Count\", width=0.8)\n\nax.set_xticklabels(wrapped_labels, rotation=0, ha='center')\n\nplt.title(\"Job Count by Industry (NAICS Level 2)\")\nplt.xticks(rotation=45, fontsize=8)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(\"figurestyj/job_count_by_industry.png\", dpi=300, bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\n\n2 Job Count by City (Top 15)\n\n\nCode\ncity_counts = df[\"CITY_NAME\"].value_counts().head(15).reset_index()\ncity_counts.columns = [\"City\", \"Job_Count\"]\n\nplt.figure(figsize=(14, 7))\nsns.barplot(data=city_counts, x=\"City\", y=\"Job_Count\", palette=\"Accent\")\nplt.title(\"Top 15 Cities by Job Count\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(\"figurestyj/top_cities_job_count.png\", dpi=300, bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\n\n3 Job Count by State\n\n\nCode\nstate_counts = df[\"STATE_NAME\"].value_counts().reset_index()\nstate_counts.columns = [\"State\", \"Job_Count\"]\n\nplt.figure(figsize=(14, 7))\nsns.barplot(data=state_counts.head(15), x=\"State\", y=\"Job_Count\", palette=\"Set2\")\nplt.title(\"Top 15 States by Job Count\")\nplt.xticks(rotation=30)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(\"figurestyj/top_states_job_count.png\", dpi=300, bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\n\n4 Heatmap: State × Industry (Cross Tab)\n\n\nCode\ncross_tab = pd.crosstab(df[\"STATE_NAME\"], df[\"NAICS_2022_2_NAME\"])\ntop_states = df[\"STATE_NAME\"].value_counts().head(10).index\ntop_industries = df[\"NAICS_2022_2_NAME\"].value_counts().head(6).index\nfiltered_heatmap = cross_tab.loc[top_states, top_industries]\n\nplt.figure(figsize=(10, 6))\nax = sns.heatmap(filtered_heatmap, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n\n\nxtick_labels = ax.get_xticklabels()\nwrapped_labels = [\n    '\\n'.join(textwrap.wrap(label.get_text(), width=15)) for label in xtick_labels\n]\nax.set_xticklabels(wrapped_labels, rotation=0)\nplt.xlabel(\"NAICS_2022_2_NAME\", fontsize=14) \npli.ylabel(\"State Name\", fontsize=14)\nplt.title(\"Top Industries in Top 10 States\")\nplt.tight_layout()\nplt.savefig(\"figurestyj/state_industry_heatmap.png\", dpi=300, bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\n\n5 Remote Job Distribution by State\n\n\nCode\nremote_by_state = df.groupby([\"STATE_NAME\", \"REMOTE_TYPE_NAME\"]).size().unstack(fill_value=0)\nremote_by_state = remote_by_state.loc[remote_by_state.sum(axis=1).sort_values(ascending=False).head(10).index]\n\nremote_by_state.plot(kind=\"bar\", stacked=True, figsize=(12, 6), colormap=\"Dark2\")\nplt.title(\"Remote Job Distribution by State\")\nplt.xlabel(\"State\")\nplt.ylabel(\"Number of Job Postings\")\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.xticks(rotation=30)\nplt.tight_layout()\nplt.savefig(\"figurestyj/remote_by_state.png\", dpi=300, bbox_inches='tight')\nplt.show()"
  }
]